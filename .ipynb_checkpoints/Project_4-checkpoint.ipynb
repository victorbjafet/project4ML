{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "878d58e7-3803-4d2c-9b19-f4c91b4090e7",
   "metadata": {},
   "source": [
    "# 1. Frame the problem\n",
    "Given a picture of a random English cursive letter, determine which letter the picture depicts. (Ex. A short loop generally depicts an e, while a tall loop depicts an l.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec99652-4719-4a66-a75d-1a2acea3ff73",
   "metadata": {},
   "source": [
    "# 2. Get the Data \n",
    "- The data was initially provided in a google drive zip folder called \"2023 Cursive\".\n",
    "- To initially load the data, I downloaded the zip file onto my local machine, and then utilized the Jupyter upload feature to upload the zip file to the remote server.\n",
    "- After the zip file was fully uploaded, I unzipped the file using the unzip package, renaming the outputted folder to 2023_Cursive for simplicity. Inside the new folder there were 9 zip files, each labelled 1 to 9.\"\n",
    "- I unzipped each folder individually using the unzip package. Each time I would unzip a folder, its name would change to what the student originally called it, so I would rename the newly created folder back to the number of its corresponding zip file. This was to keep the files/folders organized, also preventing files from mixing since some of the original folder names are identical. (Ex. Unzipping \"1.zip\" outputs a folder called \"Cursive letters\", so I renamed that folder to just \"1\".)\n",
    "- Finally, after unzipping everything, I deleted all the zip files by running \"rm *.zip -r\" in the \"2023_Cursive\" folder, leaving only the newly unzipped folders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a97dc-2a9a-441e-8f0d-740183892d01",
   "metadata": {},
   "source": [
    "# 3. Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f318bcc-d66f-4e94-99c5-8674ec7b8572",
   "metadata": {},
   "source": [
    "#### Below is a function that makes it easier to view images in the IPYNB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5ce129-5d81-498d-a089-72c84c19dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img_obj): #made this since pyplot only shows the correct color if u convert to rgb but everything in opencv is done in bgr so yea also this just helps with keeping code clean and non repeating\n",
    "    plt.imshow(cv2.cvtColor(img_obj, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43015cf6-1f6b-4cec-a256-265a37cf8d15",
   "metadata": {},
   "source": [
    "#### Below is a data explorer that just allows you to look at any image you want by simply typing a 2 character string: the number of the folder, and the letter. Alternatively, typing a single number or letter will show you the corresponding folder or all pictures of the corresponding letters.\n",
    "- (Ex. \"1a\" will show you the picture of the letter \"a\" in folder 1. \"a\" will show you all pictures of the letter \"a\" across all 9 folders, and \"1\" will show you all pictures in folder 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc638b-377d-448a-9e4a-e6aecdfe39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output #so that output is cleared after every page to prevent clutter and huge outputs\n",
    "\n",
    "#search thing to see any image without having to look for it in files\n",
    "while True:\n",
    "    uinput = input(\"Folder and Letter: \") #ex. \"2a\" to see folder 2, letter a. SPECIAL FEATURE: to see all images of a certain letter, do \"s\" + the letter you want to view, and it will show all letters.\n",
    "    clear_output()\n",
    "    print(\"Folder and Letter: \" + uinput)\n",
    "    if len(uinput) == 1:\n",
    "        try:\n",
    "            for letter in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n",
    "                image = cv2.imread(\"2023_Cursive/\" + str(int(uinput)) + \"/\" + letter + \".JPG\")\n",
    "                show(image)\n",
    "        except:\n",
    "            for i in range (1,10):\n",
    "                image = cv2.imread(\"2023_Cursive/\" + str(i) + \"/\" + uinput[0].upper() + \".JPG\")\n",
    "                show(image)\n",
    "    else:\n",
    "        image = cv2.imread(\"2023_Cursive/\" + uinput[0] + \"/\" + uinput[1].upper() + \".JPG\")\n",
    "        show(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a5122-c964-453f-bd27-5de7e595ed79",
   "metadata": {},
   "source": [
    "# 4. Prepare the Data\n",
    "#### Some data prep was done during the unzipping process in step 2 to ensure the files and folders all remained organized and consistent enough to be exploreable (see step 2 for details).\n",
    "#### The files themselves were still messy though, so some data prep had to be done between steps 2 and 3 in preparation for data exploration.\n",
    "#### Since this data prep wasn't addressed between the 2 steps, all the issues fixed between steps 2 and 3 are listed below (in the same order they were resolved) and their solutions are provided:\n",
    "- Folders 2 and 6 had several images with no file extensions.\n",
    "    - To fix this, I created a short program (located in the same folder as this IPYNB) called rename.py. I moved this program into the folders with this issue, and upon running it, it would add \".HEIC\" to the end of each file name in the folder (I also made sure to check beforehand that all files with this issue were HEIC images, so there was no need to distinguish between different file types, making the program very simple yet effective).\n",
    "- Folder 8 had three versions of every image, two versions being unnamed.\n",
    "    - To fix this, I just ran the command \"rm IMG* -r\" in the problematic directory which removed all files beginning with \"IMG\". This left only the files that were properly named.\n",
    "- Only folders 3, 7, and 9 contained their images in a JPG format. The rest of the folders all contained HEIC images, which are unsupported by OpenCV and most other image processing libraries.\n",
    "    - To fix this, I created a program (located in the same folder as this IPYNB) called convert.py. Upon being run, this program loops through every single image in the provided dataset. If an image is HEIC, it is converted into JPG. Also, for the sake of consistency, all file names are converted to uppercase so that all file names are the exact same for each set of cursive letters.\n",
    "###### _At this point, I might as well just do step 4 before step 3 every time since data prep always happens there..._\n",
    "#### Finally, we return to where we are now, step 4.\n",
    "- Now arises a much more difficult issue to deal with: standardizing the images themselves.\n",
    "- I plan to crop and scale the images to be the same resolution, aspect ratio, and have each letter in just about the same area. I'm also considering stretching the letters to keep the height and width of the letters consistent but idk yet\n",
    "- My first step initially was to binarize the images, basically just rounding each pixel to be either black or white.\n",
    "- After some online searches, it seems it would be better to just use grayscale for training, since it is more accurate.\n",
    "#### Try 1:\n",
    "- My first idea was to binarize the images, find lines in the binarized images, and if the lines made a box, I'd crop the image to the box.\n",
    "- Then after cropping the image to the box, I'd crop the images to the edges of where black pixels are found.\n",
    "- Finally, I'd get the cropped coordinates and crop the original image, plus resizing it to be a consistent resolution throughout all images\n",
    "- The reason I couldn't get this to work is because it was simply taking too long to find out how to isolate the 4 most relevant lines. It could have worked, but I didn't have enough time to spend on debugging\n",
    "- #### Try 2:\n",
    "- My second (and more functional) idea was to blur the image slightly to make everything a bit smoother, \n",
    "\n",
    "\n",
    "\n",
    "#### Note for the deployment function: when the deployment function is made, the inputted data will have to be cleaned. I will have to run the inputted image through all the same procedures that the training data went through, so I will have to redo all this data cleaning in the deployment function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b8a5a9-5876-481b-ba47-841e065cf094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def isolateLetter(gcroppedimage):\n",
    "        \n",
    "    cheight = gcroppedimage.shape[0]\n",
    "    cwidth = gcroppedimage.shape[1]\n",
    "    \n",
    "    bcroppedimage = cv2.medianBlur(gcroppedimage,65) #warped image blurred the same way the og image is blurred\n",
    "\n",
    "    cedges = cv2.Canny(bcroppedimage, 50, 70)\n",
    "    # show(cedges)\n",
    "    \n",
    "    bincroppedimage = cv2.threshold(cedges, 140, 255, cv2.THRESH_BINARY)[1] #binarized\n",
    "    # show(bincroppedimage)\n",
    "\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    dilcroppedimage = cv2.dilate(bincroppedimage, kernel, iterations=1)\n",
    "\n",
    "    # invbinimage = cv2.bitwise_not(binimage) #invert img to work\n",
    "    \n",
    "    # zeros = np.transpose(np.nonzero(invbinimage)) #array of all nonzero value indexes (except since its inverted its actually the zero values)\n",
    "    zeros = np.transpose(np.nonzero(dilcroppedimage))\n",
    "    # show(dilcroppedimage)\n",
    "\n",
    "    if np.min(zeros, axis=0)[0] < cheight/20 or np.max(zeros, axis=0)[0] > cheight-cheight/20 or np.min(zeros, axis=0, keepdims=True)[0][1] < cwidth/20 or np.max(zeros, axis=0, keepdims=True)[0][1] > cwidth-cwidth/20: #yo theres people who cropped their images but like left a really small amount of table so basically for those people check if the lettertop/bottom/l/r are 0 then if so just zoom in a bit\n",
    "        dilcroppedimage = dilcroppedimage[int(cheight/20):int(cheight-cheight/20), int(cwidth/20):int(cwidth-cwidth/20)]\n",
    "        gcroppedimage = gcroppedimage[int(cheight/20):int(cheight-cheight/20), int(cwidth/20):int(cwidth-cwidth/20)]\n",
    "        zeros = np.transpose(np.nonzero(dilcroppedimage))\n",
    "        print(\"cropped due to minor uncropped area\")\n",
    "        # show(dilcroppedimage)\n",
    "\n",
    "    cheight = gcroppedimage.shape[0]\n",
    "    cwidth = gcroppedimage.shape[1]\n",
    "\n",
    "    \n",
    "    letterTop = np.min(zeros, axis=0)[0]\n",
    "    letterBottom = np.max(zeros, axis=0)[0]\n",
    "    letterLeft = np.min(zeros, axis=0, keepdims=True)[0][1]\n",
    "    letterRight = np.max(zeros, axis=0, keepdims=True)[0][1]\n",
    "\n",
    "    \n",
    "\n",
    "    letterHeight = letterBottom-letterTop\n",
    "    letterWidth = letterRight-letterLeft\n",
    "    # print(\"letter height: \" + str(letterHeight))\n",
    "    # print(\"letter width: \" + str(letterWidth))\n",
    "\n",
    "    \n",
    "    if letterHeight > letterWidth:\n",
    "        # print(\"height bigger\")\n",
    "        letterBottom += cheight/10\n",
    "        letterTop -= cheight/10\n",
    "        newLetterHeight = letterBottom-letterTop\n",
    "        letterLeft -= (newLetterHeight-letterWidth)/2\n",
    "        letterRight += (newLetterHeight-letterWidth)/2\n",
    "    \n",
    "    elif letterHeight < letterWidth:\n",
    "        # print(\"width bigger\")\n",
    "        letterLeft -= cheight/10\n",
    "        letterRight += cheight/10\n",
    "        newLetterWidth = letterRight-letterLeft\n",
    "        letterTop -= (newLetterWidth-letterHeight)/2\n",
    "        letterBottom += (newLetterWidth-letterHeight)/2\n",
    "        \n",
    "    else:\n",
    "        # print(\"height = width (damn)\")\n",
    "        letterBottom += cheight/10\n",
    "        letterTop -= cheight/10\n",
    "        letterLeft -= cheight/10\n",
    "        letterRight += cheight/10\n",
    "\n",
    "    letterBottom = max(0, letterBottom)\n",
    "    letterTop = max(0, letterTop)\n",
    "    letterLeft = max(0, letterLeft)\n",
    "    letterRight = max(0, letterRight)\n",
    "    \n",
    "    # print(\"new letter height: \" + str(letterBottom-letterTop))\n",
    "    # print(\"new letter width: \" + str(letterRight-letterLeft))\n",
    "\n",
    "    # print(\"letterLeft: \" + str(int(letterLeft)))\n",
    "    # print(\"letterRight: \" + str(int(letterRight)))\n",
    "    # print(\"letterTop: \" + str(int(letterTop)))\n",
    "    # print(\"letterBottom: \" + str(int(letterBottom)))\n",
    "\n",
    "    \n",
    "    letterimage = gcroppedimage[int(letterTop):int(letterBottom), int(letterLeft):int(letterRight)]\n",
    "    show(letterimage)\n",
    "\n",
    "\n",
    "\n",
    "    bletterimage = cv2.medianBlur(letterimage,51)\n",
    "\n",
    "    #basically what happens below is i change all values pretty close to 255 to 255 to prevent artifacts when doing the hist equalize\n",
    "    bletterimage = cv2.bitwise_not(bletterimage)\n",
    "    bletterimage = cv2.threshold(bletterimage, 40, 255, cv2.THRESH_TOZERO)[1]\n",
    "    bletterimage = cv2.bitwise_not(bletterimage)\n",
    "    # show(bletterimage)\n",
    "\n",
    "\n",
    "    contrastletterimage = cv2.equalizeHist(bletterimage)\n",
    "    \n",
    "    # show(contrastletterimage)\n",
    "    \n",
    "    # thresh = np.average(contrastletterimage)*0.5\n",
    "    thresh = np.average(contrastletterimage)*0.8\n",
    "    # thresh = 0\n",
    "    # print(thresh)\n",
    "\n",
    "    binletterimage = cv2.threshold(bletterimage, int(thresh), 255, cv2.THRESH_BINARY)[1] # + cv2.THRESH_OTSU\n",
    "    # show(binletterimage)\n",
    "    \n",
    "    finalletterimage = cv2.resize(binletterimage, (50, 50))\n",
    "    show(finalletterimage)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for folder in \"1\":\n",
    "for folder in sorted(os.listdir(\"2023_Cursive\")): #iterate over every folder\n",
    "    for letter in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n",
    "    # for letter in \"AB\":\n",
    "        \n",
    "        image = cv2.imread(\"2023_Cursive/\" + folder + \"/\" + letter + \".JPG\") #bgr to rgb is req for correct colors to show\n",
    "        show(image)\n",
    "\n",
    "        #get height and width which end up being used a decent amount for calculating stuff\n",
    "        height = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "        \n",
    "        gimage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #make img gray\n",
    "        \n",
    "        bimage = cv2.medianBlur(gimage,99) #blur using median which gives everything a very smoothed out look which helps a lot with stuff like edge detection\n",
    "        # show(bimage)\n",
    "        \n",
    "        binimage = cv2.adaptiveThreshold(bimage, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 3, 1) #binarize the image,\n",
    "        # show(binimage)\n",
    "\n",
    "        edges = cv2.Canny(binimage, 50, 100) #find edges\n",
    "        # show(edges)\n",
    "        \n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180,200, minLineLength=width*0.5, maxLineGap=height) #find lines from edges\n",
    "        lineimage = copy.copy(image) #make copy of image specifically for drawing lines and stuff because the original image will be used for cropping and saving later\n",
    "\n",
    "        #make lists that will hold all vertical and horizontal lines\n",
    "        vertical = []\n",
    "        horizontal = []\n",
    "\n",
    "        try:\n",
    "            for line in lines:\n",
    "                for x1,y1,x2,y2 in line: #goes thru every detected line ofc\n",
    "                    if (x2-x1) != 0: #prevent division by 0 problems\n",
    "                        slope = (y2-y1)/(x2-x1) \n",
    "                    else:\n",
    "                        slope = (y2-y1)/1 #close enough to a vertical slope\n",
    "                    \n",
    "                    if slope > (height/(width*0.2)) or slope < (-height/(width*0.2)): #filters for vertical lines\n",
    "                        vertical.append((x1,y1,x2,y2)) #adds vertical line to list\n",
    "                        cv2.line(lineimage,(x1,y1),(x2,y2),(255,0,0),int(width/100)) #vertical lines are blue\n",
    "                    elif (slope < ((width*0.2)/height) and slope > ((-width*0.2)/height)): #filters for horizontal lines\n",
    "                        horizontal.append((x1,y1,x2,y2)) #adds horizontal line to list\n",
    "                        cv2.line(lineimage,(x1,y1),(x2,y2),(0,255,0),int(width/100)) #horizontal lines are blue\n",
    "        except:\n",
    "            #save to cropped folder here\n",
    "            print(\"no lines detected, assuming already cropped\")\n",
    "            isolateLetter(gimage)\n",
    "            continue\n",
    "        \n",
    "        # show(lineimage)\n",
    "\n",
    "\n",
    "        \n",
    "        def line_intersection(line1, line2): #function that gets the intersection of 2 lines\n",
    "            x1, y1 = line1[0]\n",
    "            x2, y2 = line1[1]\n",
    "            x3, y3 = line2[0]\n",
    "            x4, y4 = line2[1]\n",
    "            if x2 - x1 != 0:\n",
    "                slope1 = (y2 - y1) / (x2 - x1)\n",
    "            else:\n",
    "                slope1 = (y2 - y1) / 1\n",
    "            if x3 - x4 != 0:    \n",
    "                slope2 = (y4 - y3) / (x4 - x3)\n",
    "            else:\n",
    "                slope2 = (y4 - y3) / 1\n",
    "        \n",
    "            intercept1 = y1 - slope1 * x1\n",
    "            intercept2 = y3 - slope2 * x3\n",
    "\n",
    "            if slope1 - slope2 != 0:\n",
    "                intersection_x = (intercept2 - intercept1) / (slope1 - slope2)\n",
    "            else:\n",
    "                intersection_x = (intercept2 - intercept1) / 1\n",
    "            intersection_y = slope1 * intersection_x + intercept1\n",
    "        \n",
    "            return (int(intersection_x), int(intersection_y)) #rounded for simplicity and cv2.circle but doesnt really change anything\n",
    "            \n",
    "\n",
    "        sects = [] #list that holds coordinates of every single intersection\n",
    "\n",
    "\n",
    "        for vertLine in vertical: #only test intersections of vertical lines and horizontal lines, dont test every line against every other line because ofc vertical lines will intercept\n",
    "            for horizLine in horizontal: \n",
    "                vx1, vy1, vx2, vy2 = vertLine\n",
    "                hx1, hy1, hx2, hy2 = horizLine\n",
    "                sects.append(line_intersection(((vx1,vy1), (vx2,vy2)), ((hx1,hy1), (hx2,hy2)))) #add all intersections to the sect list\n",
    "\n",
    "\n",
    "        \n",
    "        sectimage = copy.copy(image)\n",
    "\n",
    "        tlSect = []\n",
    "        trSect = []\n",
    "        blSect = []\n",
    "        brSect = []\n",
    "        \n",
    "        for sect in sects:\n",
    "            x = sect[0]\n",
    "            y = sect[1]\n",
    "            if x < width/2:\n",
    "                if y < height/2:\n",
    "                    tlSect.append(sect)\n",
    "                else:\n",
    "                    blSect.append(sect)\n",
    "            else:\n",
    "                if y < height/2:\n",
    "                    trSect.append(sect)\n",
    "                else:\n",
    "                    brSect.append(sect)\n",
    "\n",
    "\n",
    "        \n",
    "        offset = int(width/20)\n",
    "\n",
    "        try:\n",
    "\n",
    "            tlBound = tlSect[0]\n",
    "            tlBound = (tlBound[0]+offset,tlBound[1]+offset)\n",
    "            cv2.circle(sectimage, tlBound, int(width*0.001), (0,0,255), int(width*0.03))\n",
    "    \n",
    "            blBound = blSect[0]\n",
    "            blBound = (blBound[0]+offset,blBound[1]-offset)\n",
    "            cv2.circle(sectimage, blBound, int(width*0.001), (255,255,0), int(width*0.03))\n",
    "    \n",
    "            trBound = trSect[0]\n",
    "            trBound = (trBound[0]-offset,trBound[1]+offset)\n",
    "            cv2.circle(sectimage, trBound, int(width*0.001), (255,0,0), int(width*0.03))\n",
    "    \n",
    "            brBound = brSect[0]\n",
    "            brBound = (brBound[0]-offset,brBound[1]-offset)\n",
    "            cv2.circle(sectimage, brBound, int(width*0.001), (0,255,0), int(width*0.03))\n",
    "        except:\n",
    "            #save to cropped folder here\n",
    "            print(\"missing a corner, assuming already cropped\")\n",
    "            isolateLetter(gimage)\n",
    "            continue\n",
    "        \n",
    "        show(sectimage)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        corners = np.array([tlBound, trBound, blBound, brBound], dtype=np.float32) #array with 4 coordinate pairs that are the corners of the paper\n",
    "        \n",
    "        res = np.array([(0,0), (brBound[0]-tlBound[0]-1,0), (0,brBound[1]-tlBound[1]-1), (brBound[0]-tlBound[0]-1,brBound[1]-tlBound[1]-1)], dtype=np.float32) #will be 200x200 img\n",
    "        \n",
    "        ptransform = cv2.getPerspectiveTransform(corners, res) #calculates matrix\n",
    "        \n",
    "        warpimage = cv2.warpPerspective(image, ptransform, (brBound[0]-tlBound[0],brBound[1]-tlBound[1])) #applies matrix to img\n",
    "\n",
    "        show(warpimage)\n",
    "\n",
    "        gwarpimage = cv2.cvtColor(warpimage, cv2.COLOR_BGR2GRAY) #warped img becomes gray because function needs gray image to be passed in\n",
    "\n",
    "        isolateLetter(gwarpimage)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857c891b-2b69-49b7-b4da-4e7813a4b09f",
   "metadata": {},
   "source": [
    "# Trying a different strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49809e90-ae0b-42d7-ae94-fee33e8b1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "for folder in sorted(os.listdir(\"2023_Cursive\")): #iterate over every folder\n",
    "# for folder in \"4\": #iterate over every folder\n",
    "    for letter in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n",
    "    # for letter in \"AB\": #iterate over every file\n",
    "        \n",
    "        image = cv2.imread(\"2023_Cursive/\" + folder + \"/\" + letter + \".JPG\") #read img\n",
    "        gimage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #make img gray\n",
    "        # blurred = cv2.GaussianBlur(gimage, (9, 9), 0) #blur using gaussian\n",
    "        # show(blurred)\n",
    "        blurred = cv2.medianBlur(gimage,65) #blur using median\n",
    "        show(blurred)\n",
    "\n",
    "        binimage = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 1)\n",
    "        show(binimage)\n",
    "\n",
    "        edges, _ = cv2.findContours(binimage, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        c = max(edges, key = cv2.contourArea)\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "\n",
    "        cX = x + int(w/2)\n",
    "        cY = y + int(h/2)\n",
    "        ROI = gimage[max(cY - 900, 0):min(cY + 900, gimage.shape[1] - 1), max(cX - 700, 0):min(cX + 700, gimage.shape[0] - 1)]\n",
    "        size = (1400, 1800)\n",
    "        show(ROI)\n",
    "\n",
    "        \n",
    "        imagecrop = cv2.resize(ROI, (ROI.shape[1], ROI.shape[0]), size)\n",
    "        print(\"2023_Cursive_Cropped/\" + str(folder) + \"/\" + str(letter) + \".JPG\")\n",
    "        cv2.imwrite(\"2023_Cursive_Cropped/\" + str(folder) + \"/\" + str(letter) + \".JPG\", imagecrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a67c7-6479-4933-bf48-3a8995ffc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import pandas as pd\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "# flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16df2b3-dd07-4196-916b-35efd7fb9825",
   "metadata": {},
   "source": [
    "# 5. Model the data\n",
    "#### Unfortunately I can't model the data since I never managed to finish the cropping, and had no time.\n",
    "- I would have tried a neural network.\n",
    "- Also, I just want to note that I would have to flatten the image to make it fit into a model.\n",
    "- I would've put everything into a dataframe too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb6a4d-4b92-40f8-9210-3fd4a4bb1ae8",
   "metadata": {},
   "source": [
    "# 6. Fine Tune the Model\n",
    "\n",
    "- There isn't really anything to fine tune... because there is no model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b035360-0d3f-45e0-b383-ebaace72cb7d",
   "metadata": {},
   "source": [
    "# 7. Present the (theoretical) solution\n",
    "- First, I imported my data and organized/converted all my files\n",
    "- Then, I looked through all the pictures I had to see what changes had to be made (cropping, resizing)\n",
    "- Then, I split the data into a test and train set, and then tried fitting 3 different models to see which would give the best results\n",
    "- Then, I decided on the model that was best at predicting the data primarily based on RMSE/MAE and maybe some of the plotting data (didn't really use the plotted data since there was no found correlation)\n",
    "- Finally, deploy the chosen model to a file for usage elsewhere\n",
    "#### THE CHOSEN MODEL WAS LINEAR REGRESSION ROUNDED TO THE CLOSEST WHOLE INTEGER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1524b249-daef-40c9-a238-23582ae66992",
   "metadata": {},
   "source": [
    "# 8. Launch the Model System\n",
    "- Of course since unfortunately there is no model, there is no way to display the deployment of the ML system.\n",
    "- What I would do though, is \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
