{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "878d58e7-3803-4d2c-9b19-f4c91b4090e7",
   "metadata": {},
   "source": [
    "# 1. Frame the problem\n",
    "Given a picture of a random English cursive letter, determine which letter the picture depicts. (Ex. A short loop generally depicts an e, while a tall loop depicts an l.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec99652-4719-4a66-a75d-1a2acea3ff73",
   "metadata": {},
   "source": [
    "# 2. Get the Data \n",
    "- The data was initially provided in a google drive zip folder called \"2023 Cursive\".\n",
    "- To initially load the data, I downloaded the zip file onto my local machine, and then utilized the Jupyter upload feature to upload the zip file to the remote server.\n",
    "- After the zip file was fully uploaded, I unzipped the file using the unzip package, renaming the outputted folder to 2023_Cursive for simplicity. Inside the new folder there were 9 zip files, each labelled 1 to 9.\"\n",
    "- I unzipped each folder individually using the unzip package. Each time I would unzip a folder, its name would change to what the student originally called it, so I would rename the newly created folder back to the number of its corresponding zip file. This was to keep the files/folders organized, also preventing files from mixing since some of the original folder names are identical. (Ex. Unzipping \"1.zip\" outputs a folder called \"Cursive letters\", so I renamed that folder to just \"1\".)\n",
    "- Finally, after unzipping everything, I deleted all the zip files by running \"rm *.zip -r\" in the \"2023_Cursive\" folder, leaving only the newly unzipped folders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a97dc-2a9a-441e-8f0d-740183892d01",
   "metadata": {},
   "source": [
    "# 3. Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f318bcc-d66f-4e94-99c5-8674ec7b8572",
   "metadata": {},
   "source": [
    "#### Below is a function that makes it easier to view images in the IPYNB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed5ce129-5d81-498d-a089-72c84c19dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img_obj): #made this since pyplot only shows the correct color if u convert to rgb but everything in opencv is done in bgr so yea also this just helps with keeping code clean and non repeating\n",
    "    plt.imshow(cv2.cvtColor(img_obj, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43015cf6-1f6b-4cec-a256-265a37cf8d15",
   "metadata": {},
   "source": [
    "#### Below is a data explorer that just allows you to look at any image you want by simply typing a 2 character string: the number of the folder, and the letter. Alternatively, typing a single number or letter will show you the corresponding folder or all pictures of the corresponding letters.\n",
    "- (Ex. \"1a\" will show you the picture of the letter \"a\" in folder 1. \"a\" will show you all pictures of the letter \"a\" across all 9 folders, and \"1\" will show you all pictures in folder 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc638b-377d-448a-9e4a-e6aecdfe39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output #so that output is cleared after every page to prevent clutter and huge outputs\n",
    "\n",
    "#search thing to see any image without having to look for it in files\n",
    "set = \"2023_Cursive/\"\n",
    "set = \"2023_Cursive_Cleaned/\"\n",
    "while True:\n",
    "    uinput = input(\"Folder and Letter: \") #ex. \"2a\" to see folder 2, letter a. SPECIAL FEATURE: to see all images of a certain letter, do \"s\" + the letter you want to view, and it will show all letters.\n",
    "    if len(uinput) != 1 and len(uinput) != 2:\n",
    "        break\n",
    "    clear_output()\n",
    "    print(\"Folder and Letter: \" + uinput)\n",
    "    if len(uinput) == 1:\n",
    "        try:\n",
    "            for letter in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n",
    "                image = cv2.imread(set + str(int(uinput)) + \"/\" + letter + \".JPG\")\n",
    "                show(image)\n",
    "        except:\n",
    "            for i in range (1,10):\n",
    "                image = cv2.imread(set + str(i) + \"/\" + uinput[0].upper() + \".JPG\")\n",
    "                show(image)\n",
    "    elif len(uinput) == 2:\n",
    "        image = cv2.imread(set + uinput[0] + \"/\" + uinput[1].upper() + \".JPG\")\n",
    "        show(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a5122-c964-453f-bd27-5de7e595ed79",
   "metadata": {},
   "source": [
    "# 4. Prepare the Data\n",
    "#### Some data prep was done during the unzipping process in step 2 to ensure the files and folders all remained organized and consistent enough to be exploreable (see step 2 for details).\n",
    "#### The files themselves were still messy though, so some data prep had to be done between steps 2 and 3 in preparation for data exploration.\n",
    "#### Since this data prep wasn't addressed between the 2 steps, all the issues fixed between steps 2 and 3 are listed below (in the same order they were resolved) and their solutions are provided:\n",
    "- Folders 2 and 6 had several images with no file extensions.\n",
    "    - To fix this, I created a short program (located in the same folder as this IPYNB) called rename.py. I moved this program into the folders with this issue, and upon running it, it would add \".HEIC\" to the end of each file name in the folder (I also made sure to check beforehand that all files with this issue were HEIC images, so there was no need to distinguish between different file types, making the program very simple yet effective).\n",
    "- Folder 8 had three versions of every image, two versions being unnamed.\n",
    "    - To fix this, I just ran the command \"rm IMG* -r\" in the problematic directory which removed all files beginning with \"IMG\". This left only the files that were properly named.\n",
    "- Only folders 3, 7, and 9 contained their images in a JPG format. The rest of the folders all contained HEIC images, which are unsupported by OpenCV and most other image processing libraries.\n",
    "    - To fix this, I created a program (located in the same folder as this IPYNB) called convert.py. Upon being run, this program loops through every single image in the provided dataset. If an image is HEIC, it is converted into JPG. Also, for the sake of consistency, all file names are converted to uppercase so that all file names are the exact same for each set of cursive letters.\n",
    "###### _At this point, I might as well just do step 4 before step 3 every time since data prep always happens there..._\n",
    "#### Finally, we return to where we are now, step 4. This step took me no joke, over 10 hours of work to complete.\n",
    "- Now arises a much more difficult issue to deal with: standardizing the images themselves.\n",
    "- Of course, to do this, I loop through every image and deal with it individually, not doing anything by hand, meaning I am not using external knowledge of the file's group to know what transformations need to be done.\n",
    "#### Part 1: Cropping\n",
    "- So before trying to isolate the letters themselves, I focused specifically on the image sets (4, 7, and 8) that did not have cropped letters and made an algorithm to detect if an image is not cropped and then crop it properly (of course not applying specific transformations).\n",
    "- A lot of testing and tweaking was done, but in the end I settled on this:\n",
    "    1. Gray, blur, and treshold the image.\n",
    "    2. Detect edges and then detect lines from edges. Isolate all lines that are nearly vertical or nearly horizontal, and seperate them into 2 lists. (If no lines are detected, assume the image is cropped and move on)\n",
    "    3. Compare the lines in each list to find all intersection points (slope based, meaning the lines do not have to be touching as long as the slopes would eventually collide)\n",
    "    4. Pick an intersection point from each quadrant of the image to use as corners, and do a slight offset to ensure that there is no (or in rare cases minimal) table still showing (If one or more corners are missing, assume the image is cropped and move on)\n",
    "    5. Do a perspective transform to finally get the cropped image, and pass it into the function which deals with the second step\n",
    "- Lots of tweaking had to be done due to issues with not all corners being detected, but in the end it works on all 3 non cropped data sets.\n",
    "#### Part 2: Isolating Letter\n",
    "- Now that the images are _almost_ (as will be addressed soon) all perfectly cropped, now I have to isolate the letter itself to make a 1:1 aspect ratio image with the letter being a (mostly) standard size.\n",
    "- This step was done entirely in a function so it could be called at different points because there are situations where you don't need to crop before doing this step, meaning you would want to begin this earlier.\n",
    "- This took immense amounts of tests, but it works well enough despite a few inpurities, so here is the process:\n",
    "    1. The grayed, cropped image is to be passed in (so either just a gray version of the original image or a grayed version of the perspective transformed image depending on what happened in the previous step)\n",
    "    2. The image is blurred, edge detected, binarized from the canny image, and then dilated so that it's easier to spot the letter outlines that are created\n",
    "    3. Using mins and maxes on np arrays, the highest, lowest, left most, and right most black pixels are found and saved.\n",
    "        - But for this step, remember how some images have a slight amount of table still showing? If the black pixels are too close to the edge, the image is slightly cropped to remove possible missed bits, which solves the issue in all known cases. Of course, the updated black pixel extremes are found.\n",
    "    4. Then, a square region is found around the letter to be cropped to. The image is cropped to this region. Sometimes, if an edge is hit, it won't be a square, which will cause a stretch in the final resize, but it's nothing significant enough to distort the letter in a bad way.\n",
    "    5. The image is binarized.\n",
    "        - This step has multiple steps inside it and took a lot of tweaking to get right:\n",
    "        1. The cropped image is blurred.\n",
    "        2. All pixels >= 235 are thresholded to 255 to prevent artifacts in the next step (remember, the image is grayscale)\n",
    "        3. This is what really allows the image to be binarized correctly even though adaptiveThreshold sucks: the histogram of grayscale scalars in the image is equalized, so even if the handwriting is a light gray due to flash or other reasons, it will still binarize correctly.\n",
    "        4. The final binarization threshold is applied, with the threshold being a scalar of the average pixel value of the image (this part is what causes the most problems as some letters get some parts thresholded out since this isn't perfect, but then again adaptiveThreshold would only draw outlines which prevented me from using it so I had to do these workarounds)\n",
    "    6. Finally, the image is downscaled to 50x50 pixels and saved to a new folder which contains all of these newly cropped images.\n",
    "### Finally, the data prep is done! That was just data prep!\n",
    "#### Note for the deployment function: when the deployment function is made, the inputted data will have to be cleaned. I will have to run the inputted image through all the same procedures that the training data went through, so I will have to redo all this data cleaning in the deployment function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b8a5a9-5876-481b-ba47-841e065cf094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def isolateLetter(gcroppedimage):\n",
    "        \n",
    "    cheight = gcroppedimage.shape[0]\n",
    "    cwidth = gcroppedimage.shape[1]\n",
    "    \n",
    "    bcroppedimage = cv2.medianBlur(gcroppedimage,65) #warped image blurred the same way the og image is blurred\n",
    "\n",
    "    cedges = cv2.Canny(bcroppedimage, 30, 50)\n",
    "    # show(cedges)\n",
    "    \n",
    "    bincroppedimage = cv2.threshold(cedges, 140, 255, cv2.THRESH_BINARY)[1] #binarized\n",
    "    # show(bincroppedimage)\n",
    "\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    dilcroppedimage = cv2.dilate(bincroppedimage, kernel, iterations=1)\n",
    "\n",
    "    # invbinimage = cv2.bitwise_not(binimage) #invert img to work\n",
    "    \n",
    "    # zeros = np.transpose(np.nonzero(invbinimage)) #array of all nonzero value indexes (except since its inverted its actually the zero values)\n",
    "    zeros = np.transpose(np.nonzero(dilcroppedimage))\n",
    "    # show(dilcroppedimage)\n",
    "\n",
    "    if np.min(zeros, axis=0)[0] < cheight/20 or np.max(zeros, axis=0)[0] > cheight-cheight/20 or np.min(zeros, axis=0, keepdims=True)[0][1] < cwidth/20 or np.max(zeros, axis=0, keepdims=True)[0][1] > cwidth-cwidth/20:\n",
    "        dilcroppedimage = dilcroppedimage[int(cheight/20):int(cheight-cheight/20), int(cwidth/20):int(cwidth-cwidth/20)]\n",
    "        gcroppedimage = gcroppedimage[int(cheight/20):int(cheight-cheight/20), int(cwidth/20):int(cwidth-cwidth/20)]\n",
    "        zeros = np.transpose(np.nonzero(dilcroppedimage))\n",
    "        print(\"cropped due to minor uncropped area\")\n",
    "        # show(dilcroppedimage)\n",
    "\n",
    "    cheight = gcroppedimage.shape[0]\n",
    "    cwidth = gcroppedimage.shape[1]\n",
    "\n",
    "    \n",
    "    letterTop = np.min(zeros, axis=0)[0]\n",
    "    letterBottom = np.max(zeros, axis=0)[0]\n",
    "    letterLeft = np.min(zeros, axis=0, keepdims=True)[0][1]\n",
    "    letterRight = np.max(zeros, axis=0, keepdims=True)[0][1]\n",
    "\n",
    "    \n",
    "\n",
    "    letterHeight = letterBottom-letterTop\n",
    "    letterWidth = letterRight-letterLeft\n",
    "    # print(\"letter height: \" + str(letterHeight))\n",
    "    # print(\"letter width: \" + str(letterWidth))\n",
    "\n",
    "    \n",
    "    if letterHeight > letterWidth:\n",
    "        # print(\"height bigger\")\n",
    "        letterBottom += cwidth/10\n",
    "        letterTop -= cwidth/10\n",
    "        newLetterHeight = letterBottom-letterTop\n",
    "        letterLeft -= (newLetterHeight-letterWidth)/2\n",
    "        letterRight += (newLetterHeight-letterWidth)/2\n",
    "    \n",
    "    elif letterHeight < letterWidth:\n",
    "        # print(\"width bigger\")\n",
    "        letterLeft -= cwidth/10\n",
    "        letterRight += cwidth/10\n",
    "        newLetterWidth = letterRight-letterLeft\n",
    "        letterTop -= (newLetterWidth-letterHeight)/2\n",
    "        letterBottom += (newLetterWidth-letterHeight)/2\n",
    "        \n",
    "    else:\n",
    "        # print(\"height = width (damn)\")\n",
    "        letterBottom += cwidth/10\n",
    "        letterTop -= cwidth/10\n",
    "        letterLeft -= cwidth/10\n",
    "        letterRight += cwidth/10\n",
    "\n",
    "    letterBottom = max(0, letterBottom)\n",
    "    letterTop = max(0, letterTop)\n",
    "    letterLeft = max(0, letterLeft)\n",
    "    letterRight = max(0, letterRight)\n",
    "    \n",
    "    # print(\"new letter height: \" + str(letterBottom-letterTop))\n",
    "    # print(\"new letter width: \" + str(letterRight-letterLeft))\n",
    "\n",
    "    # print(\"letterLeft: \" + str(int(letterLeft)))\n",
    "    # print(\"letterRight: \" + str(int(letterRight)))\n",
    "    # print(\"letterTop: \" + str(int(letterTop)))\n",
    "    # print(\"letterBottom: \" + str(int(letterBottom)))\n",
    "\n",
    "    \n",
    "    letterimage = gcroppedimage[int(letterTop):int(letterBottom), int(letterLeft):int(letterRight)]\n",
    "    show(letterimage)\n",
    "\n",
    "\n",
    "\n",
    "    bletterimage = cv2.medianBlur(letterimage,51)\n",
    "\n",
    "    #basically what happens below is i change all values pretty close to 255 to 255 to prevent artifacts when doing the hist equalize\n",
    "    bletterimage = cv2.bitwise_not(bletterimage)\n",
    "    bletterimage = cv2.threshold(bletterimage, 40, 255, cv2.THRESH_TOZERO)[1]\n",
    "    bletterimage = cv2.bitwise_not(bletterimage)\n",
    "    # show(bletterimage)\n",
    "\n",
    "\n",
    "    contrastletterimage = cv2.equalizeHist(bletterimage)\n",
    "    \n",
    "    # show(contrastletterimage)\n",
    "    \n",
    "    # thresh = np.average(contrastletterimage)*0.5\n",
    "    thresh = np.average(contrastletterimage)*0.75 #0.8 works well\n",
    "    # thresh = 0\n",
    "    # print(thresh)\n",
    "\n",
    "    binletterimage = cv2.threshold(bletterimage, int(thresh), 255, cv2.THRESH_BINARY)[1] # + cv2.THRESH_OTSU\n",
    "    # show(binletterimage)\n",
    "    \n",
    "    finalletterimage = cv2.resize(binletterimage, (50, 50))\n",
    "    show(finalletterimage)\n",
    "\n",
    "    return finalletterimage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for folder in \"7\":\n",
    "for folder in sorted(os.listdir(\"2023_Cursive\")): #iterate over every folder\n",
    "    # for letter in \"S\":\n",
    "    for letter in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n",
    "        \n",
    "        image = cv2.imread(\"2023_Cursive/\" + folder + \"/\" + letter + \".JPG\") #bgr to rgb is req for correct colors to show\n",
    "        show(image)\n",
    "\n",
    "        #get height and width which end up being used a decent amount for calculating stuff\n",
    "        height = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "        \n",
    "        gimage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #make img gray\n",
    "        \n",
    "        bimage = cv2.medianBlur(gimage,99) #blur using median which gives everything a very smoothed out look which helps a lot with stuff like edge detection #too high blur can cause edge detections problems\n",
    "        # show(bimage)\n",
    "        \n",
    "        binimage = cv2.adaptiveThreshold(bimage, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 3, 1) #binarize the image,\n",
    "        # show(binimage)\n",
    "\n",
    "\n",
    "        # kernel = np.ones((15,15), np.uint8)\n",
    "        # erobinimage = cv2.erode(binimage, kernel, iterations=1)\n",
    "        # show(erobinimage)\n",
    "\n",
    "        edges = cv2.Canny(binimage, 50, 100) #find edges\n",
    "        # show(edges)\n",
    "        \n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180,110, minLineLength=width*0.5, maxLineGap=height) #find lines from edges\n",
    "        lineimage = copy.copy(image) #make copy of image specifically for drawing lines and stuff because the original image will be used for cropping and saving later\n",
    "\n",
    "        #make lists that will hold all vertical and horizontal lines\n",
    "        vertical = []\n",
    "        horizontal = []\n",
    "\n",
    "        try:\n",
    "            for line in lines:\n",
    "                for x1,y1,x2,y2 in line: #goes thru every detected line ofc\n",
    "                    if (x2-x1) != 0: #prevent division by 0 problems\n",
    "                        slope = (y2-y1)/(x2-x1) \n",
    "                    else:\n",
    "                        slope = (y2-y1)/1 #close enough to a vertical slope\n",
    "                    \n",
    "                    if slope > (height/(width*0.2)) or slope < (-height/(width*0.2)): #filters for vertical lines\n",
    "                        vertical.append((x1,y1,x2,y2)) #adds vertical line to list\n",
    "                        cv2.line(lineimage,(x1,y1),(x2,y2),(255,0,0),int(width/100)) #vertical lines are blue\n",
    "                    elif (slope < ((width*0.2)/height) and slope > ((-width*0.2)/height)): #filters for horizontal lines\n",
    "                        horizontal.append((x1,y1,x2,y2)) #adds horizontal line to list\n",
    "                        cv2.line(lineimage,(x1,y1),(x2,y2),(0,255,0),int(width/100)) #horizontal lines are blue\n",
    "        except:\n",
    "            #save to cropped folder here\n",
    "            print(\"no lines detected, assuming already cropped\")\n",
    "            cv2.imwrite(\"2023_Cursive_Cleaned/\" + folder + \"/\" + letter + \".JPG\", isolateLetter(gimage))\n",
    "            continue\n",
    "        \n",
    "        # show(lineimage)\n",
    "\n",
    "\n",
    "        \n",
    "        def line_intersection(line1, line2): #function that gets the intersection of 2 lines\n",
    "            x1, y1 = line1[0]\n",
    "            x2, y2 = line1[1]\n",
    "            x3, y3 = line2[0]\n",
    "            x4, y4 = line2[1]\n",
    "            if x2 - x1 != 0:\n",
    "                slope1 = (y2 - y1) / (x2 - x1)\n",
    "            else:\n",
    "                slope1 = (y2 - y1) / 1\n",
    "            if x3 - x4 != 0:    \n",
    "                slope2 = (y4 - y3) / (x4 - x3)\n",
    "            else:\n",
    "                slope2 = (y4 - y3) / 1\n",
    "        \n",
    "            intercept1 = y1 - slope1 * x1\n",
    "            intercept2 = y3 - slope2 * x3\n",
    "\n",
    "            if slope1 - slope2 != 0:\n",
    "                intersection_x = (intercept2 - intercept1) / (slope1 - slope2)\n",
    "            else:\n",
    "                intersection_x = (intercept2 - intercept1) / 1\n",
    "            intersection_y = slope1 * intersection_x + intercept1\n",
    "        \n",
    "            return (int(intersection_x), int(intersection_y)) #rounded for simplicity and cv2.circle but doesnt really change anything\n",
    "            \n",
    "\n",
    "        sects = [] #list that holds coordinates of every single intersection\n",
    "\n",
    "\n",
    "        for vertLine in vertical: #only test intersections of vertical lines and horizontal lines, dont test every line against every other line because ofc vertical lines will intercept\n",
    "            for horizLine in horizontal: \n",
    "                vx1, vy1, vx2, vy2 = vertLine\n",
    "                hx1, hy1, hx2, hy2 = horizLine\n",
    "                sects.append(line_intersection(((vx1,vy1), (vx2,vy2)), ((hx1,hy1), (hx2,hy2)))) #add all intersections to the sect list\n",
    "\n",
    "\n",
    "        \n",
    "        sectimage = copy.copy(image)\n",
    "\n",
    "        tlSect = []\n",
    "        trSect = []\n",
    "        blSect = []\n",
    "        brSect = []\n",
    "        \n",
    "        for sect in sects:\n",
    "            x = sect[0]\n",
    "            y = sect[1]\n",
    "            if x < width/2:\n",
    "                if y < height/2:\n",
    "                    tlSect.append(sect)\n",
    "                else:\n",
    "                    blSect.append(sect)\n",
    "            else:\n",
    "                if y < height/2:\n",
    "                    trSect.append(sect)\n",
    "                else:\n",
    "                    brSect.append(sect)\n",
    "\n",
    "\n",
    "        \n",
    "        offset = int(width/20)\n",
    "\n",
    "        try:\n",
    "\n",
    "            tlBound = tlSect[0]\n",
    "            tlBound = (tlBound[0]+offset,tlBound[1]+offset)\n",
    "            cv2.circle(sectimage, tlBound, int(width*0.001), (0,0,255), int(width*0.03))\n",
    "    \n",
    "            blBound = blSect[0]\n",
    "            blBound = (blBound[0]+offset,blBound[1]-offset)\n",
    "            cv2.circle(sectimage, blBound, int(width*0.001), (255,255,0), int(width*0.03))\n",
    "    \n",
    "            trBound = trSect[0]\n",
    "            trBound = (trBound[0]-offset,trBound[1]+offset)\n",
    "            cv2.circle(sectimage, trBound, int(width*0.001), (255,0,0), int(width*0.03))\n",
    "    \n",
    "            brBound = brSect[0]\n",
    "            brBound = (brBound[0]-offset,brBound[1]-offset)\n",
    "            cv2.circle(sectimage, brBound, int(width*0.001), (0,255,0), int(width*0.03))\n",
    "        except:\n",
    "            #save to cropped folder here\n",
    "            print(\"missing a corner, assuming already cropped\")\n",
    "            cv2.imwrite(\"2023_Cursive_Cleaned/\" + folder + \"/\" + letter + \".JPG\", isolateLetter(gimage))\n",
    "            continue\n",
    "        \n",
    "        show(sectimage)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        corners = np.array([tlBound, trBound, blBound, brBound], dtype=np.float32) #array with 4 coordinate pairs that are the corners of the paper\n",
    "        \n",
    "        res = np.array([(0,0), (brBound[0]-tlBound[0]-1,0), (0,brBound[1]-tlBound[1]-1), (brBound[0]-tlBound[0]-1,brBound[1]-tlBound[1]-1)], dtype=np.float32) #will be 200x200 img\n",
    "        \n",
    "        ptransform = cv2.getPerspectiveTransform(corners, res) #calculates matrix\n",
    "        \n",
    "        warpimage = cv2.warpPerspective(image, ptransform, (brBound[0]-tlBound[0],brBound[1]-tlBound[1])) #applies matrix to img\n",
    "\n",
    "        show(warpimage)\n",
    "\n",
    "        gwarpimage = cv2.cvtColor(warpimage, cv2.COLOR_BGR2GRAY) #warped img becomes gray because function needs gray image to be passed in\n",
    "\n",
    "        cv2.imwrite(\"2023_Cursive_Cleaned/\" + folder + \"/\" + letter + \".JPG\", isolateLetter(gwarpimage))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857c891b-2b69-49b7-b4da-4e7813a4b09f",
   "metadata": {},
   "source": [
    "# Trying a different strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49809e90-ae0b-42d7-ae94-fee33e8b1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "for folder in sorted(os.listdir(\"2023_Cursive\")): #iterate over every folder\n",
    "# for folder in \"4\": #iterate over every folder\n",
    "    for letter in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n",
    "    # for letter in \"AB\": #iterate over every file\n",
    "        \n",
    "        image = cv2.imread(\"2023_Cursive/\" + folder + \"/\" + letter + \".JPG\") #read img\n",
    "        gimage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #make img gray\n",
    "        # blurred = cv2.GaussianBlur(gimage, (9, 9), 0) #blur using gaussian\n",
    "        # show(blurred)\n",
    "        blurred = cv2.medianBlur(gimage,65) #blur using median\n",
    "        show(blurred)\n",
    "\n",
    "        binimage = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 1)\n",
    "        show(binimage)\n",
    "\n",
    "        edges, _ = cv2.findContours(binimage, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        c = max(edges, key = cv2.contourArea)\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "\n",
    "        cX = x + int(w/2)\n",
    "        cY = y + int(h/2)\n",
    "        ROI = gimage[max(cY - 900, 0):min(cY + 900, gimage.shape[1] - 1), max(cX - 700, 0):min(cX + 700, gimage.shape[0] - 1)]\n",
    "        size = (1400, 1800)\n",
    "        show(ROI)\n",
    "\n",
    "        \n",
    "        imagecrop = cv2.resize(ROI, (ROI.shape[1], ROI.shape[0]), size)\n",
    "        print(\"2023_Cursive_Cropped/\" + str(folder) + \"/\" + str(letter) + \".JPG\")\n",
    "        cv2.imwrite(\"2023_Cursive_Cropped/\" + str(folder) + \"/\" + str(letter) + \".JPG\", imagecrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a67c7-6479-4933-bf48-3a8995ffc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import pandas as pd\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "# flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16df2b3-dd07-4196-916b-35efd7fb9825",
   "metadata": {},
   "source": [
    "# 5. Model the data\n",
    "#### Unfortunately I can't model the data since I never managed to finish the cropping, and had no time.\n",
    "- I would have tried a neural network.\n",
    "- Also, I just want to note that I would have to flatten the image to make it fit into a model.\n",
    "- I would've put everything into a dataframe too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb6a4d-4b92-40f8-9210-3fd4a4bb1ae8",
   "metadata": {},
   "source": [
    "# 6. Fine Tune the Model\n",
    "\n",
    "- There isn't really anything to fine tune... because there is no model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b035360-0d3f-45e0-b383-ebaace72cb7d",
   "metadata": {},
   "source": [
    "# 7. Present the (theoretical) solution\n",
    "- First, I imported my data and organized/converted all my files\n",
    "- Then, I looked through all the pictures I had to see what changes had to be made (cropping, resizing)\n",
    "- Then, I split the data into a test and train set, and then tried fitting 3 different models to see which would give the best results\n",
    "- Then, I decided on the model that was best at predicting the data primarily based on RMSE/MAE and maybe some of the plotting data (didn't really use the plotted data since there was no found correlation)\n",
    "- Finally, deploy the chosen model to a file for usage elsewhere\n",
    "#### THE CHOSEN MODEL WAS LINEAR REGRESSION ROUNDED TO THE CLOSEST WHOLE INTEGER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1524b249-daef-40c9-a238-23582ae66992",
   "metadata": {},
   "source": [
    "# 8. Launch the Model System\n",
    "- Of course since unfortunately there is no model, there is no way to display the deployment of the ML system.\n",
    "- What I would do though, is \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
